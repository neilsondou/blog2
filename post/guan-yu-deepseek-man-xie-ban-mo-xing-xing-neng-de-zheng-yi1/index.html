<html>

<head>
  <meta charset="utf-8" />
<meta name="description" content="知乎 窦天阳 / 由腾讯云EdgeOne驱动" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests" />
<title>
  关于Deepseek满血版、模型性能的争议 | 老窦
</title>
<link rel="shortcut icon" href="https://neilsondou.me/favicon.ico">

<link rel="stylesheet" href="https://neilsondou.me/styles/main.css">
<link rel="apple-touch-icon" href="https://neilsondou.me/favicon.ico">
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

<!-- iconfont -->
<link href="//at.alicdn.com/t/font_2463772_glcffdg0qau.css" rel="stylesheet" />
<script src="https://cdn.bootcss.com/moment.js/2.23.0/moment.min.js"></script>
<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/@highlightjs/cdn-assets/highlight.min.js"></script>


            
</head>

<body>
  <div class="main">
    <div class="main-content">
      <div class="nav-bar">
  <!-- 首页菜单 -->
  <div class="menu-container">
    <a href="https://neilsondou.me/index.html" target="_parent" class="home">
      <svg class="home-icon" fill="none" viewBox="0 0 24 24" stroke="currentColor" width="24" height="24">
        <path fill="#fff" d="M12 14l9-5-9-5-9 5 9 5z"></path>
        <path fill="#fff"
          d="M12 14l6.16-3.422a12.083 12.083 0 01.665 6.479A11.952 11.952 0 0012 20.055a11.952 11.952 0 00-6.824-2.998 12.078 12.078 0 01.665-6.479L12 14z">
        </path>
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
          d="M12 14l9-5-9-5-9 5 9 5zm0 0l6.16-3.422a12.083 12.083 0 01.665 6.479A11.952 11.952 0 0012 20.055a11.952 11.952 0 00-6.824-2.998 12.078 12.078 0 01.665-6.479L12 14zm-4 6v-7.5l4-2.222">
        </path>
      </svg>
      <span class="home-title">首页</span>
    </a>

    <div class="nav-menu">
      
      
      <a href="/post/about" class="menu">
        关于
      </a>
      
      



      <a href="https://neilsondou.me/atom.xml" target="_blank" class="rss">
        <span class="rss-title">RSS</span>
        <i class="iconfont icon-rss"></i>
      </a>
    </div>
  </div>
</div>

      <div class="post-detail">
        <article class="post">
          
          <h2 class="post-title">
            关于Deepseek满血版、模型性能的争议
          </h2>

          <div class="post-info">
            <svg class="post-date" fill="none" viewBox="0 0 24 24" stroke="currentColor" width="16" height="16">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                d="M8 7V3m8 4V3m-9 8h10M5 21h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"></path>
            </svg>
            <time class="post-time">
              2025-02-26
            </time>
            <svg fill="none" class="view-icon" viewBox="0 0 24 24" stroke="currentColor" width="16" height="16">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                d="M15 12a3 3 0 11-6 0 3 3 0 016 0z">
              </path>
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                d="M2.458 12C3.732 7.943 7.523 5 12 5c4.478 0 8.268 2.943 9.542 7-1.274 4.057-5.064 7-9.542 7-4.477 0-8.268-2.943-9.542-7z">
              </path>
            </svg>
            <span id="/guan-yu-deepseek-man-xie-ban-mo-xing-xing-neng-de-zheng-yi1/" class="leancloud_visitors" data-flag-title="关于Deepseek满血版、模型性能的争议">
              <span class="leancloud-visitors-count"></span><span> 次阅读</span>
            </span>
            <span>
              6 min read
            </span>
          </div>

          
          <div class="post-content">
            <p>首先明确一点：客观定义上的这个r1模型的满血版，是617b参数、fp8精度且未经过量化蒸馏微调的原生模型，是开源了的，而现在市面上的99%第三方平台提供的deepseek模型都不是满血的，包括几乎所有自称满血版的。<br>
第三方平台，比如腾讯元宝、硅基流动、腾讯云等等所提供的其实就是算力，但是为了推广让更多人使用，而且钻一下deepseek官网经常无法进行问答的空子，来宣传自己家的平台，如果像colab一样去直接出租算力，首先不说普通用户能不能负担的起时长的浪费、而且不已tokens计算的计费并不符合大模型出现以来一直沿用的收费逻辑。所以这些平台所提供在自己集群上部署的deepseek模型，并且出租或者开放使用大模型的问答这件事本身是合理的商业行为，但是问题就出在这里，如果直接出租算力给用户，那么用户可以选择去部署什么样的模型，可以根据自己的需求和使用场景来部署参数的模型，而这些第三方平台所推出的所谓满血版deepseek模型，实际上是无法验证是不是满血版的，用户无法获取到这些信息。<br>
经过一些人的测试，腾讯元宝的r1在性能上接近于官方所提供的服务，但是在内容审查，引用内容质量上相较于直接从搜索引擎获取，而从公众号平台上获取，且内容审查机制更加严格，实际上影响了r1模型的原始性能，毕竟公众号平台上的内容相对来说比较少，此外经过测试，在一些需要长思维链推理的问题中，腾讯元宝的r1与deepseek r1相比较为逊色，可以说在严格的内容审查、公众号的信息污染的影响下，腾讯元宝的r1不可以说是满血版，当然这个满血版只是严格意义上的定义，作为广告噱头来说是没问题的。当然这其中也存在着一些腾讯结束deepseek热度抢占ai隐私高地的嫌疑。<br>
其他各种服务商所提供的r1模型，都与腾讯元宝类似，或多或少因为服务商自身的各种目的，在部署过程中改变信息获取等等机制，对模型自身的性能产生了影响，有的服务商甚至部署了30b的r1模型，骗人说是满血版，该类服务商所提供的服务不应该继续使用。</p>
<p>那么在哪里能使用到满血版的deepseek模型呢，目前为止只有三种方法：官方api、本地部署、算力租赁，官方的api好像最近在降价，关于怎么去使用可以查看官方文档，或者在python中用下面的方法调用</p>
<p>import requests</p>
<h1 id="填写你的-api-key">填写你的 API Key</h1>
<p>API_KEY = &quot;sk-你的密钥&quot;</p>
<p>url = &quot;https://api.deepseek.com/chat/completions&quot;<br>
headers = {<br>
&quot;Content-Type&quot;: &quot;application/json&quot;,<br>
&quot;Authorization&quot;: f&quot;Bearer {API_KEY}&quot;<br>
}</p>
<p>data = {<br>
&quot;model&quot;: &quot;deepseek-reasoner&quot;,  # 指定使用 R1 模型（deepseek-reasoner）或者 V3 模型（deepseek-chat）<br>
&quot;messages&quot;: [<br>
{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是一个专业的助手&quot;},<br>
{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你是谁？&quot;}<br>
],<br>
&quot;stream&quot;: False  # 关闭流式传输<br>
}</p>
<p>response = requests.post(url, headers=headers, json=data)</p>
<p>if response.status_code == 200:<br>
result = response.json()<br>
print(result['choices'][0]['message']['content'])<br>
else:<br>
print(&quot;请求失败，错误码：&quot;, response.status_code)</p>
<p>如果用户想要在本地部署deepseek满血版的话，除了购买几张死贵的英伟达显卡，可以在接受范围内的大概就只有两种方案，一种是买几台macmini，串联起来可以部署满血版的模型，或者通过服务器平台的cpu和大量内存进行部署，但是输出速度感人，目前这个满血版的模型在服务器平台cpu算力的部署中的瓶颈据说在硬盘的读写速度上，有人正在研究把模型存在内存里，该方案有待验证。<br>
算力租赁的话，有各种服务商可以考虑，但是价格基本不是普通用户能够负担得起的，这里就不举例子了。</p>
<p>关于deepseek r1模型的性能，远远没有网上吹的那么邪乎，说世界第一，具体的elo可以查看https://openlm.ai/chatbot-arena/，在这个排行中，除了尚未被加入的calude 3.7，deepseek r1的性能排在第五，在chatgpt、geminiexp、gork之下，对于开源大模型来说这个排名已经不错了，但是要做一个大模型，我们在不论性能的前提下首先要考虑的是用户的体验，我从deepseek v2发布开始就一直在使用，一直到deepseek v3、r1开始在互联网上火起来之后，用户体验就直线下滑，官方提供的api响应速度慢，网页上几乎无法使用大模型，从而催生出来各种第三方服务商来提供r1模型给人使用，让人钻了空子，这是deepseek的问题，除此之外，响应速度、大模型幻觉的这些问题仍然存在。到现在为止，deepseek从第一个大模型发布以来，用户体验就从来没有超过chatgpt，除了网络问题，我在高强度使用用chatgpt的时候从来没有出现过任何响应上的问题，这就是下一步deepseek必须要注意的问题了。</p>

          </div>
        </article>
      </div>

      <div class="near-post">
        <div>
          
          <div class="prev-post">
            <div class="prev">上一篇</div>
            <a href="https://neilsondou.me/post/wen-da-ni-ru-he-kan-dai-dao-ban-shu/">
              <h3 class="post-title">
                <span>
                  问答：你如何看待盗版书？
                </span>
              </h3>
            </a>
          </div>
          
        </div>
        <div>
          
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://neilsondou.me/post/guan-yu-ren-gong-zhi-neng-zheng-zai-chuang-zao-yi-dai-wen-mang-cheng-xu-yuan/">
              <h3 class="post-title">
                <span>
                  关于“人工智能正在创造一代文盲程序员”
                </span>
              </h3>
            </a>
          </div>
          
        </div>
      </div>

      

      <div class="valine">
        
      </div>

      <div class="site-footer">
  
  <b>Theme: </b>
  <a href="//github.com/chiperman/gridea-theme-porky"><b>Porky</b></a
  ><b> | Powered by </b>
  <a href="//open.gridea.dev"><b>Gridea</b></a>
</div>

<script>
  hljs.initHighlightingOnLoad();
</script>

    </div>
  </div>
</body>

</html>